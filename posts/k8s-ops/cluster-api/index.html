<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Self-managed Kubernetes with Cluster API in GCP (+ Cilium) - Deployment</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content="Cluster API is a Kubernetes sub-project focused on providing declarative APIs and tooling to simplify provisioning, upgrading, and operating multiple Kubernetes clusters."><meta property="og:title" content="Self-managed Kubernetes with Cluster API in GCP (+ Cilium)"><meta property="og:description" content="Cluster API is a Kubernetes sub-project focused on providing declarative APIs and tooling to simplify provisioning, upgrading, and operating multiple Kubernetes clusters."><meta property="og:type" content="article"><meta property="og:url" content="https://deployment.properties/posts/k8s-ops/cluster-api/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-10-01T11:32:38-04:00"><meta property="article:modified_time" content="2022-10-05T10:35:54-04:00"><meta itemprop=name content="Self-managed Kubernetes with Cluster API in GCP (+ Cilium)"><meta itemprop=description content="Cluster API is a Kubernetes sub-project focused on providing declarative APIs and tooling to simplify provisioning, upgrading, and operating multiple Kubernetes clusters."><meta itemprop=datePublished content="2022-10-01T11:32:38-04:00"><meta itemprop=dateModified content="2022-10-05T10:35:54-04:00"><meta itemprop=wordCount content="1650"><meta itemprop=keywords content="kubernetes,ops,k8s,cluster-api,gcp,google cloud,cilium,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Self-managed Kubernetes with Cluster API in GCP (+ Cilium)"><meta name=twitter:description content="Cluster API is a Kubernetes sub-project focused on providing declarative APIs and tooling to simplify provisioning, upgrading, and operating multiple Kubernetes clusters."><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/custom.css><link rel="shortcut icon" href=/favicon.ico><script async src="https://www.googletagmanager.com/gtag/js?id=G-0BJEGTESYY"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-0BJEGTESYY",{anonymize_ip:!1})}</script></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=/ title=Deployment rel=home><div class="logo__item logo__text"><div class=logo__title>Deployment</div><div class=logo__tagline>A tech blog focused on DevSecOps</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/about/><span class=menu__text>About</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Self-managed Kubernetes with Cluster API in GCP (+ Cilium)</h1><div class="post__meta meta"><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2.0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class=meta__text>Romulo Santos</span></div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2022-10-01T11:32:38-04:00>2022-10-01</time>
<time class=meta__text datetime=2022-10-05T10:35:54-04:00>(Last Modified: 2022-10-05)</time></div></div></header><div class="content post__content clearfix"><p>We all know the benefits of using managed Kubernetes services like GKE, EKS, AKS, etc. Given the complexity of managing the cluster infrastructure and its core components (control plane, auto-scaling, monitoring, networking, storage, etc.), using a managed Kubernetes service is generally the first choice when running workloads in production.</p><p>However, in some situations, provisioning and managing the Kubernetes cluster from scratch might be necessary. Specific product features, security & compliance, costs, vendor independency, etc. are some factors that usually justify the decision of running Kubernetes by yourself. Of course, many challenges come with managing a Kubernetes cluster and the discussion around which route - self-managed vs. managed - to take is far from simple. I want to keep this discussion out of the scope of this tutorial since it would require special attention.</p><p>Currently, the tool of choice when considering provisioning and managing a Kubernetes cluster is <a href=https://cluster-api.sigs.k8s.io/>Cluster API</a>. From the docs:</p><blockquote><p><em>Cluster API is a Kubernetes sub-project focused on providing declarative APIs and tooling to simplify provisioning, upgrading, and operating multiple Kubernetes clusters.</em></p><p><em>[&mldr;] The supporting infrastructure, like virtual machines, networks, load balancers, and VPCs, as well as the Kubernetes cluster configuration are all defined in the same way that application developers operate deploying and managing their workloads. This enables consistent and repeatable cluster deployments across a wide variety of infrastructure environments.</em></p></blockquote><p>Cluster API supports a comprehensive <a href=https://cluster-api.sigs.k8s.io/reference/providers.html>list of providers</a> covering the main public Cloud providers and other popular platforms.</p><p>This tutorial will use the Cluster API to provision a cluster in GCP and install Cilium as the network solution. It follows the same idea as the <a href=https://cluster-api.sigs.k8s.io/user/quick-start.html>Cluster API Quick Start Guide</a> for GCP with more complete and detailed steps.</p><p>Before we start, note that Cluster API introduces important <a href=https://cluster-api.sigs.k8s.io/user/concepts.html>concepts</a> that I&rsquo;ll use here with minimal explanation. So, I recommend reading the concepts and other relevant parts of the documentation. It&rsquo;s not a requirement to follow along, tho.</p><h2 id=prerequisites>Prerequisites</h2><p>For this tutorial, you need to create or select a Google Cloud Project and ensure the following tools are installed.</p><ul><li><a href=https://cloud.google.com/sdk/gcloud#downloading_the_gcloud_command-line_tool>gcloud</a></li><li><a href=https://kubernetes.io/docs/tasks/tools/#kubectl>kubectl</a> (v1.23)</li><li><a href=https://kind.sigs.k8s.io/docs/user/quick-start/#installation>kind</a> (v0.14.0+)</li><li><a href=https://cluster-api.sigs.k8s.io/user/quick-start.html#install-clusterctl>clusterctl</a> (v1.2.2+)</li><li><a href=https://www.packer.io/intro/getting-started/install.html>packer</a> (v1.8.3)</li><li><a href=https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html>ansible</a> (v2.13.4)</li><li><a href=https://helm.sh/docs/intro/install/>helm</a> (v3.10.0)</li></ul><h2 id=preparing-the-gcp-project>Preparing the GCP project</h2><p>In the terminal export the following variables:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>export GCP_PROJECT_ID<span style=color:#f92672>=</span>cluster-api-363616
</span></span><span style=display:flex><span>export GCP_REGION<span style=color:#f92672>=</span>us-east1
</span></span><span style=display:flex><span>export GCP_NETWORK_NAME<span style=color:#f92672>=</span>default
</span></span><span style=display:flex><span>export CLUSTER_NAME<span style=color:#f92672>=</span>starks
</span></span></code></pre></div><h3 id=create-a-cloud-nat>Create a Cloud NAT</h3><p>To ensure the cluster can communicate with the outside world and the load balancer, let&rsquo;s create a Cloud NAT. Note that we are using the <code>default</code> network.</p><p>If it&rsquo;s a new project enable the compute API.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>gcloud services enable compute.googleapis.com --project <span style=color:#e6db74>&#34;</span>$GCP_PROJECT_ID<span style=color:#e6db74>&#34;</span>
</span></span></code></pre></div><p>Create a Cloud Router and Cloud NAT.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>gcloud compute routers create <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>CLUSTER_NAME<span style=color:#e6db74>}</span><span style=color:#e6db74>-router&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --region <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>GCP_REGION<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> --network <span style=color:#e6db74>&#34;default&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --project <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>GCP_PROJECT_ID<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gcloud compute routers nats create <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>CLUSTER_NAME<span style=color:#e6db74>}</span><span style=color:#e6db74>-nat&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --router-region <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>GCP_REGION<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> --router <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>CLUSTER_NAME<span style=color:#e6db74>}</span><span style=color:#e6db74>-router&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --nat-all-subnet-ip-ranges --auto-allocate-nat-external-ips <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --project <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>GCP_PROJECT_ID<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span></code></pre></div><p>These instructions can be found in the <a href=https://github.com/kubernetes-sigs/cluster-api-provider-gcp/blob/main/docs/book/src/topics/prerequisites.md#setup-a-network-and-cloud-nat>GCP Cluster API Provider documentation</a>.</p><h3 id=create-a-service-account>Create a Service Account</h3><p>We need a service account key to grant the Cluster API access to the GCP project. As per <a href=https://github.com/kubernetes-sigs/cluster-api-provider-gcp/blob/main/docs/book/src/topics/prerequisites.md#create-a-service-account>these instructions</a> this Service Account needs <code>Editor</code> permissions.</p><p>Generate the service account and attach the <code>Editor</code> role.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>gcloud iam service-accounts create <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>CLUSTER_NAME<span style=color:#e6db74>}</span><span style=color:#e6db74>-sa&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --display-name <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>CLUSTER_NAME<span style=color:#e6db74>}</span><span style=color:#e6db74>-sa&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --project <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>GCP_PROJECT_ID<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gcloud projects add-iam-policy-binding <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>GCP_PROJECT_ID<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --member <span style=color:#e6db74>&#34;serviceAccount:</span><span style=color:#e6db74>${</span>CLUSTER_NAME<span style=color:#e6db74>}</span><span style=color:#e6db74>-sa@</span><span style=color:#e6db74>${</span>GCP_PROJECT_ID<span style=color:#e6db74>}</span><span style=color:#e6db74>.iam.gserviceaccount.com&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --role <span style=color:#e6db74>&#34;roles/editor&#34;</span>
</span></span></code></pre></div><p>Create a service account key and store it in a file called <code>key.json</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>gcloud iam service-accounts keys create key.json <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --iam-account <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>CLUSTER_NAME<span style=color:#e6db74>}</span><span style=color:#e6db74>-sa@</span><span style=color:#e6db74>${</span>GCP_PROJECT_ID<span style=color:#e6db74>}</span><span style=color:#e6db74>.iam.gserviceaccount.com&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --project <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>GCP_PROJECT_ID<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span></code></pre></div><h3 id=build-a-kubernetes-gce-image>Build a Kubernetes GCE Image</h3><p>We need a GCE image with the Kubernetes dependencies and configuration that will be used in the nodes instances. For this, we will use the <a href=https://github.com/kubernetes-sigs/image-builder>Kubernetes Image Builder</a> project.</p><p>Export the <code>GOOGLE_APPLICATION_CREDENTIALS</code> variable pointing to the service account key file.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>export GOOGLE_APPLICATION_CREDENTIALS<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span>$PWD<span style=color:#e6db74>&#34;</span>/key.json
</span></span></code></pre></div><p>Clone the Image Builder repository.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>git clone https://github.com/kubernetes-sigs/image-builder.git image-builder; cd image-builder/images/capi
</span></span></code></pre></div><p>Build the image.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>make build-gce-ubuntu-2004
</span></span></code></pre></div><style type=text/css>.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#444;background:#e7f2fa;text-align:left}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:#fff;background:#6ab0de;text-align:left}.notice.warning .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info .notice-title{background:#f0b37e}.notice.info{background:#fff2db}.notice.note .notice-title{background:#6ab0de}.notice.note{background:#e7f2fa}.notice.tip .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative}</style><div><svg width="0" height="0" display="none" xmlns="http://www.w3.org/2000/svg"><symbol id="tip-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379.0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628.0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628.0l-22.627 22.627c-6.248 6.248-6.248 16.379.0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z"/></symbol><symbol id="note-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zm-248 50c-25.405.0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346 7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373.0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884.0-12.356 5.78-11.981 12.654z"/></symbol><symbol id="warning-notice" viewBox="0 0 576 512" preserveAspectRatio="xMidYMid meet"><path d="M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937.0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154.0l239.94 416.028zM288 354c-25.405.0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346 7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373.0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884.0-12.356 5.78-11.981 12.654z"/></symbol><symbol id="info-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196.0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627.0 12 5.373 12 12v1e2h12c6.627.0 12 5.373 12 12v24z"/></symbol></svg></div><div class="notice note" id=tip-id><p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#note-notice"/></svg></span>Note on the Kubernetes version and customization</p><p>In this tutorial, we use the default Kubernetes version defined in the configuration cloned from the repository at the time of this writing (v1.23.10). To change the Kubernetes version or customize other build parameters check the <a href=https://github.com/kubernetes-sigs/image-builder/blob/master/docs/book/src/capi/capi.md#customization>customization section</a> of the Image Builer CAPI documentation.</p></div><p><strong>This step takes several minutes. You can probably move forward with other steps until before the <code>kubectl apply</code> that starts the creation of the cluster.</strong></p><p>Retrieve the image name and set the image ID variable.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>IMAGE_NAME<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>gcloud compute images list --no-standard-images <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --sort-by<span style=color:#f92672>=</span>~creationTimestamp --filter<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;family:capi-ubuntu-2004-k8s&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --project <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>GCP_PROJECT_ID<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> --format json | jq -r <span style=color:#e6db74>&#39;.[0].name&#39;</span><span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>export IMAGE_ID<span style=color:#f92672>=</span>projects/<span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>GCP_PROJECT_ID<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>/global/images/<span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>IMAGE_NAME<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span></code></pre></div><p>For more details about this process check the doc for the <a href=https://image-builder.sigs.k8s.io/capi/providers/gcp.html>Image Builder GCP</a>.</p><p>Return to the original directory (where the <code>key.json</code> file is stored).</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cd -
</span></span></code></pre></div><div class="notice tip" id=ssh-ansible><p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#tip-notice"/></svg></span>SSH errors during the Ansible execution</p><p>I&rsquo;m on Ubuntu 22.04 and had to add these lines to my SSH config for the Ansible script connect with the remote server.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat ~/.ssh/config
</span></span><span style=display:flex><span>HostKeyAlgorithms +ssh-rsa
</span></span><span style=display:flex><span>PubkeyAcceptedKeyTypes +ssh-rsa
</span></span></code></pre></div></div><h2 id=spin-up-the-management-cluster>Spin up the Management Cluster</h2><p>A <a href=https://cluster-api.sigs.k8s.io/user/concepts.html#management-cluster>Management Cluster</a> is a Kubernetes cluster that manages the lifecycle of the cluster that we are going to create with the Cluster API (aka <a href=https://cluster-api.sigs.k8s.io/user/concepts.html#workload-cluster>Workload Cluster</a>).</p><p>Set a variable with the Kubernetes version.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>KUBERNETES_VERSION<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>jq -r .kubernetes_semver image-builder/images/capi/packer/config/kubernetes.json<span style=color:#66d9ef>)</span>
</span></span></code></pre></div><p>We will use <code>kind</code> to create a Management Cluster locally. This is only for development and experimentation. In production, you should use an actual production-ready Kubernetes cluster.</p><p>Create the local cluster.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kind create cluster --name management-cluster --image kindest/node:<span style=color:#e6db74>&#34;</span>$KUBERNETES_VERSION<span style=color:#e6db74>&#34;</span>
</span></span></code></pre></div><p>Initialize the Management Cluster using the GCP provider.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>export GCP_B64ENCODED_CREDENTIALS<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>base64 key.json | tr -d <span style=color:#e6db74>&#39;\n&#39;</span><span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>clusterctl init --infrastructure gcp
</span></span></code></pre></div><p>Inspect the Management Cluster and check the CAPI and CAPG controllers that have been created.</p><div class="notice warning" id=capi-bootstrap-creds><p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#warning-notice"/></svg></span>CAPI Manager Bootstrap Credentials</p><p>Note that the service account key has been stored in the <code>capg-manager-bootstrap-credentials</code> kube secret in the namespace <code>capg-system</code>. This is a really high-privileged static credential to have stored in the cluster. In a production environment, this is something that you definetely want to keep track of and secure properly.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get secrets capg-manager-bootstrap-credentials <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  -n capg-system -o json | jq -r <span style=color:#e6db74>&#39;.data.&#34;credentials.json&#34;&#39;</span> | base64 -d
</span></span></code></pre></div></div><h2 id=create-the-workload-cluster>Create the Workload Cluster</h2><p>Export the following variables.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>export GCP_PROJECT<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span>$GCP_PROJECT_ID<span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>export GCP_CONTROL_PLANE_MACHINE_TYPE<span style=color:#f92672>=</span>n1-standard-2
</span></span><span style=display:flex><span>export GCP_NODE_MACHINE_TYPE<span style=color:#f92672>=</span>n1-standard-2
</span></span></code></pre></div><p>The name of these variables and others we have exported before (e.g. <code>IMAGE_ID</code> and <code>KUBERNETES_VERSION</code>) must match what is defined in the <a href=https://github.com/kubernetes-sigs/cluster-api-provider-gcp/blob/main/templates/cluster-template.yaml>cluster-template.yaml</a>.</p><p>Generate the cluster configuration.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>clusterctl generate cluster <span style=color:#e6db74>&#34;</span>$CLUSTER_NAME<span style=color:#e6db74>&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --kubernetes-version <span style=color:#e6db74>&#34;</span>$KUBERNETES_VERSION<span style=color:#e6db74>&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --control-plane-machine-count<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --worker-machine-count<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  &gt; <span style=color:#e6db74>&#34;</span>$CLUSTER_NAME<span style=color:#e6db74>&#34;</span>.yaml
</span></span></code></pre></div><p>Inspect the YAML file created. This YAML contains the specification for the GCP infrastructure that will be created. You apply this to the Management Cluster and the CAPI and CAPG controllers deployed to it will take care of the infrastructure provisioning.</p><p>The best reference for these APIs are the Go docs for <a href=https://pkg.go.dev/sigs.k8s.io/cluster-api@v1.2.2/api/v1beta1>CAPI</a> and <a href=https://pkg.go.dev/sigs.k8s.io/cluster-api-provider-gcp@v1.2.0/api/v1beta1>CAPG</a>. You can also use <code>kube explain</code> to obtain information for these kinds.</p><p>In a production environment, you&rsquo;ll adjust and version control this file with all of your specific requirements.</p><p>Apply it.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f <span style=color:#e6db74>&#34;</span>$CLUSTER_NAME<span style=color:#e6db74>&#34;</span>.yaml 
</span></span></code></pre></div><p>It will create the resources:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>cluster.cluster.x-k8s.io
</span></span><span style=display:flex><span>gcpcluster.infrastructure.cluster.x-k8s.io
</span></span><span style=display:flex><span>kubeadmcontrolplane.controlplane.cluster.x-k8s.io
</span></span><span style=display:flex><span>gcpmachinetemplate.infrastructure.cluster.x-k8s.io
</span></span><span style=display:flex><span>machinedeployment.cluster.x-k8s.io
</span></span><span style=display:flex><span>gcpmachinetemplate.infrastructure.cluster.x-k8s.io
</span></span><span style=display:flex><span>kubeadmconfigtemplate.bootstrap.cluster.x-k8s.io
</span></span></code></pre></div><p>This will initialize the creation of the GCP resources for the Workload Cluster.</p><p>Inspect and explore the resources created. These are some useful commands to check the progress of cluster provisioning.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get cluster
</span></span><span style=display:flex><span>kubectl describe cluster <span style=color:#e6db74>&#34;</span>$CLUSTER_NAME<span style=color:#e6db74>&#34;</span> 
</span></span><span style=display:flex><span>kubectl get machines
</span></span><span style=display:flex><span>kubectl get gcpmachines
</span></span><span style=display:flex><span>kubectl get machinedeployments 
</span></span><span style=display:flex><span>kubectl describe kubeadmcontrolplane <span style=color:#e6db74>&#34;</span>$CLUSTER_NAME<span style=color:#e6db74>&#34;</span>-control-plane
</span></span></code></pre></div><p>Check the GCP project and note the resources created as part of the provisioning. Some useful commands to explore the GCP resoruces.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>gcloud compute instance-groups list --project <span style=color:#e6db74>&#34;</span>$GCP_PROJECT_ID<span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>gcloud compute instances list  --filter<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;tags.items=</span>$CLUSTER_NAME<span style=color:#e6db74>&#34;</span> --project <span style=color:#e6db74>&#34;</span>$GCP_PROJECT_ID<span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>gcloud compute firewall-rules list --project <span style=color:#e6db74>&#34;</span>$GCP_PROJECT<span style=color:#e6db74>&#34;</span>
</span></span></code></pre></div><p>Checking the CAPI and CAPG controllers logs is probably your best bet if you need to debug problems.</p><p>It will take a couple minutes. Wait until the all the 6 nodes are up and running.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get machines
</span></span><span style=display:flex><span>NAME                           CLUSTER   NODENAME                     PROVIDERID                                                       PHASE     AGE     VERSION
</span></span><span style=display:flex><span>starks-control-plane-7d7f4     starks    starks-control-plane-8qbrq   gce://project-id/us-east1-c/starks-control-plane-8qbrq   Running   4m53s   v1.23.10
</span></span><span style=display:flex><span>starks-control-plane-jdqnz     starks    starks-control-plane-rxhl4   gce://project-id/us-east1-d/starks-control-plane-rxhl4   Running   3m2s    v1.23.10
</span></span><span style=display:flex><span>starks-control-plane-kgdhb     starks    starks-control-plane-c7t74   gce://project-id/us-east1-b/starks-control-plane-c7t74   Running   9m24s   v1.23.10
</span></span><span style=display:flex><span>starks-md-0-6f6f4956f8-2lj5w   starks    starks-md-0-lbxw9            gce://project-id/us-east1-b/starks-md-0-lbxw9            Running   10m     v1.23.10
</span></span><span style=display:flex><span>starks-md-0-6f6f4956f8-ctstr   starks    starks-md-0-fqd89            gce://project-id/us-east1-b/starks-md-0-fqd89            Running   10m     v1.23.10
</span></span><span style=display:flex><span>starks-md-0-6f6f4956f8-tqw5n   starks    starks-md-0-nlknx            gce://project-id/us-east1-b/starks-md-0-nlknx            Running   10m     v1.23.10
</span></span></code></pre></div><h2 id=install-cilium>Install Cilium</h2><p>Now, we need to install a CNI to get the Workload Cluster ready to work.</p><p>Export the kubeconfig.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>clusterctl get kubeconfig <span style=color:#e6db74>&#34;</span>$CLUSTER_NAME<span style=color:#e6db74>&#34;</span> &gt; <span style=color:#e6db74>&#34;</span>$CLUSTER_NAME<span style=color:#e6db74>&#34;</span>.kubeconfig
</span></span></code></pre></div><p>Open a new terminal session and in this same directory export the <code>KUBECONFIG</code> environment variable.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>export KUBECONFIG<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span>$PWD<span style=color:#e6db74>/</span>$CLUSTER_NAME<span style=color:#e6db74>&#34;</span>.kubeconfig
</span></span></code></pre></div><p>Now your kubectl is pointing to the Workload Cluster.</p><p>Inspect the pods created in this cluster <code>kubectl get po n- kube-system</code>. Also, check the nodes and note that they are reporting <code>NotReady</code> status.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get nodes
</span></span></code></pre></div><p>Install Cilium.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>helm repo add cilium https://helm.cilium.io/
</span></span><span style=display:flex><span>helm install cilium cilium/cilium --version 1.12.2 --namespace kube-system
</span></span></code></pre></div><p>Check that the Cilium pods are running.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l k8s-app<span style=color:#f92672>=</span>cilium -n kube-system
</span></span></code></pre></div><p>Check the nodes again and verify that now they are ready.</p><p>Refer to the <a href=https://docs.cilium.io/en/stable/gettingstarted/>Cilium docs</a> for more details.</p><h2 id=check-the-cluster>Check the cluster</h2><p>To verify that our cluster is completely operational, let&rsquo;s deploy and expose an application.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/controllers/nginx-deployment.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl expose deployment nginx-deployment --type<span style=color:#f92672>=</span>LoadBalancer --name<span style=color:#f92672>=</span>nginx-service
</span></span></code></pre></div><p>Wait until the service provides an external IP and run.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -s <span style=color:#66d9ef>$(</span>kubectl get services nginx-service -o json | jq -r <span style=color:#e6db74>&#39;.status.loadBalancer.ingress[0] | .ip&#39;</span><span style=color:#66d9ef>)</span> | grep <span style=color:#e6db74>&#39;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&#39;</span>
</span></span><span style=display:flex><span>&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
</span></span></code></pre></div><p>This LoadBalancer service creates a Network Load Balancer in GCP and is good for this type of test or a few use cases. To expose your application you probably want to use an Ingress Controller such as <a href=https://github.com/kubernetes/ingress-nginx>Ingress NGINX Controller</a>, which provides a richer set of features.</p><h2 id=clean-up>Clean up</h2><p>Pointing you kubeconfig to the workload cluster.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete svc nginx-service
</span></span></code></pre></div><p>(it will remove the load balancer and the firewall rules)</p><p>Pointing you kubeconfig to the management cluster.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete cluster <span style=color:#e6db74>&#34;</span>$CLUSTER_NAME<span style=color:#e6db74>&#34;</span>
</span></span></code></pre></div><p>Remove the management cluster.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kind delete cluster --name management-cluster
</span></span></code></pre></div><p>Remove the GCP objects that we created.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>gcloud compute routers nats delete <span style=color:#e6db74>&#34;</span>$CLUSTER_NAME<span style=color:#e6db74>&#34;</span>-nat --router<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span>$CLUSTER_NAME<span style=color:#e6db74>&#34;</span>-router --router-region<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span>$GCP_REGION<span style=color:#e6db74>&#34;</span> --project <span style=color:#e6db74>&#34;</span>$GCP_PROJECT_ID<span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>gcloud compute routers delete <span style=color:#e6db74>&#34;</span>$CLUSTER_NAME<span style=color:#e6db74>&#34;</span>-router --region<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span>$GCP_REGION<span style=color:#e6db74>&#34;</span> --project <span style=color:#e6db74>&#34;</span>$GCP_PROJECT_ID<span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>gcloud iam service-accounts delete <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>CLUSTER_NAME<span style=color:#e6db74>}</span><span style=color:#e6db74>-sa@</span><span style=color:#e6db74>${</span>GCP_PROJECT_ID<span style=color:#e6db74>}</span><span style=color:#e6db74>.iam.gserviceaccount.com&#34;</span> --project <span style=color:#e6db74>&#34;</span>$GCP_PROJECT_ID<span style=color:#e6db74>&#34;</span>
</span></span></code></pre></div><p>If you have any questions or comments feel free to reach out in the Twitter thread below or directly.</p><blockquote class=twitter-tweet><p lang=en dir=ltr>A walk through the Cluster API spinning up a self-managed Kubernetes cluster in GCP.<a href=https://t.co/feANEaaSdB>https://t.co/feANEaaSdB</a></p>&mdash; Romulo Santos (@soeirosantos_) <a href="https://twitter.com/soeirosantos_/status/1576269542590148611?ref_src=twsrc%5Etfw">October 1, 2022</a></blockquote><script async src=https://platform.twitter.com/widgets.js></script></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/kubernetes/ rel=tag>kubernetes</a></li><li class=tags__item><a class="tags__link btn" href=/tags/ops/ rel=tag>ops</a></li><li class=tags__item><a class="tags__link btn" href=/tags/k8s/ rel=tag>k8s</a></li><li class=tags__item><a class="tags__link btn" href=/tags/cluster-api/ rel=tag>cluster-api</a></li><li class=tags__item><a class="tags__link btn" href=/tags/gcp/ rel=tag>gcp</a></li><li class=tags__item><a class="tags__link btn" href=/tags/google-cloud/ rel=tag>google cloud</a></li><li class=tags__item><a class="tags__link btn" href=/tags/cilium/ rel=tag>cilium</a></li></ul></div></footer></article></main></div></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2022 Deployment - A tech blog focused on DevSecOps.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script>
<script src=/js/custom.js></script></body></html>