<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>k8s on Deployment</title><link>https://deployment.properties/tags/k8s/</link><description>Recent content in k8s on Deployment</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 01 Oct 2022 11:32:38 -0400</lastBuildDate><atom:link href="https://deployment.properties/tags/k8s/index.xml" rel="self" type="application/rss+xml"/><item><title>Self-managed Kubernetes with Cluster API in GCP (+ Cilium)</title><link>https://deployment.properties/posts/k8s-ops/cluster-api/</link><pubDate>Sat, 01 Oct 2022 11:32:38 -0400</pubDate><guid>https://deployment.properties/posts/k8s-ops/cluster-api/</guid><description>&lt;p>We all know the benefits of using managed Kubernetes services like GKE, EKS, AKS, etc. Given the complexity of managing the cluster infrastructure and its core components (control plane, auto-scaling, monitoring, networking, storage, etc.), using a managed Kubernetes service is generally the first choice when running workloads in production.&lt;/p>
&lt;p>However, in some situations, provisioning and managing the Kubernetes cluster from scratch might be necessary. Specific product features, security &amp;amp; compliance, costs, vendor independency, etc. are some factors that usually justify the decision to run Kubernetes by yourself. Of course, many challenges come with managing a Kubernetes cluster. I want to keep this discussion out of the scope of this tutorial since it requires special attention.&lt;/p>
&lt;p>Nowadays, when considering provision and managing a Kubernetes cluster, the tool of choice is &lt;a href="https://cluster-api.sigs.k8s.io/">Cluster API&lt;/a>. From the docs:&lt;/p>
&lt;blockquote>
&lt;p>&lt;em>Cluster API is a Kubernetes sub-project focused on providing declarative APIs and tooling to simplify provisioning, upgrading, and operating multiple Kubernetes clusters.&lt;/em>&lt;/p>
&lt;p>&lt;em>[&amp;hellip;] The supporting infrastructure, like virtual machines, networks, load balancers, and VPCs, as well as the Kubernetes cluster configuration are all defined in the same way that application developers operate deploying and managing their workloads. This enables consistent and repeatable cluster deployments across a wide variety of infrastructure environments.&lt;/em>&lt;/p>
&lt;/blockquote></description></item></channel></rss>